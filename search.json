[{"title":"MarkDown基础语法","url":"/2023/02/03/MarkDown%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","content":"标题样式#的数量表示标题的级别，注意 # 后加空格，最多支持到六级标题\n# 一级标题\n## 二级标题\n### 三级标题\n一级标题二级标题三级标题字体样式MarkDown字体样式有三种，斜体、粗体、粗斜体\n* 斜体 *                     斜体\n*粗体*                   粗体\n**粗斜体**          粗斜体\n分割线三个以上的 * 或 _ 构成分割线，且本行无其他内容\n***\n___\n\n\n引用在引用的段落前添加 &gt; 完成引用\n&gt; 这场漫长的战争伴随着整个人类文明，现在仍然胜负末定，虫子并没有被灭绝，它们照样傲行于天地之间，它们的数量也并不比人类出现前少。把人类看做虫子的三体人似乎忘记了一个事实：虫子从来就没有被真正战胜过。 \n\n这场漫长的战争伴随着整个人类文明，现在仍然胜负末定，虫子并没有被灭绝，它们照样傲行于天地之间，它们的数量也并不比人类出现前少。把人类看做虫子的三体人似乎忘记了一个事实：虫子从来就没有被真正战胜过。 \n\n也可采用多级引用\n\n引用一\n\n引用二\n\n引用三\n\n\n\n列表MarkDowe的列表有有序列表和无序列表\n有序列表\n第一项\n\n第二项\n\n\n无序列表* 第一项\n* 第二项\n\n第一项\n\n第二项\n\n\n代码块行内代码使用 &#96; 放在代码两端\n    这是一行经典的代码`print(“hello,world!”)`\n    这是一行经典的代码print(&quot;hello,world!&quot;)\n行间代码（代码块）使用 &#96;&#96;&#96; 放在代码块上下，可标注代码类型\na = &#x27;hello&#x27;b = &#x27;world!&#x27;print(f&#x27;&#123;a&#125;,&#123;b&#125;!&#x27;)\n","tags":["MarkDown"]},{"title":"线性回归梯度下降的np和Pytorch实现","url":"/2023/02/03/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84np%E5%92%8CPytorch%E5%AE%9E%E7%8E%B0/","content":"2022吴恩达机器学习 课程笔记\n本文为线性回归梯度下降的Python的代码实现\n基本公式 \n \n\n\n每次计算完令 , 进行数据更新，重复迭代，可令参数值不断逼近实际值\n基于np的代码实现import numpy as npimport matplotlib.pyplot as plt# 生成随机数据# 定义线性函数 y = x*2 + 20 + randomx = np.random.randint(0, 100, (10))y = x * 2 + 20 + np.random.randint(-5, 5,(10))print(x, y)# 计算损失函数def loss(x, y, w, b):    predict = x*w + b    loss = np.average((predict - y) ** 2) / 2    return predict, loss# 实现梯度下降# 定义部分参数epochs = 1000    # 迭代次数learning_rate = 0.0003    # 学习率w = 0b = 0    #初始化 w 和 bfor i in range(epochs):    predict, l = loss(x, y, w, b)    temp_w = w - learning_rate*np.average((predict-y)*x)    temp_b = b - learning_rate*np.average(predict-y)    w = temp_w    b = temp_bprint(w, b)# 绘制图片plt.plot(x,y, 'o')plt.plot(x,2*x+20, 'r')plt.plot(x,w*x+b,'b')plt.show()\n\n运行结果如下图所示：\n\n基于Pytorch的代码实现pytorch 可根据链式计算法则自动的计算梯度并将结果储存在w.grad中\nimport numpy as npimport torchimport matplotlib.pyplot as plt# 生成随机数据# 定义函数 y = x*2 + 20 + randomx = np.random.randint(0, 30, (10))y = x * 2 + 20 + np.random.randint(-5, 5,(10))w, b = 0, 0# 将数据转换为pytorch格式X = torch.tensor(x, dtype=torch.float32)Y = torch.tensor(y, dtype=torch.float32)w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)b = torch.tensor(10.0, dtype=torch.float32, requires_grad=True)# 向前传播def forward(x):    return w * x +b# 定义loss函数def loss(y, y_pred):    return ((y_pred - y)**2).mean()# 定义训练参数learning_rate = 0.0003epochs = 1000for epoch in range(epochs):    # 预测 向前传播    y_pred = forward(X)    # 计算loss    l = loss(Y, y_pred)    # 计算梯度 向后传播    l.backward()    # 更新权重    with torch.no_grad():        w -= learning_rate * w.grad        b -= learning_rate * b.grad    # 清零梯度    w.grad.zero_()    b.grad.zero_()    # 输出结果    if epoch % 10 == 0:        print(f'epoch {epoch+1}: w = {w.item():.3f}, b = {b.item():.3f} loss = {l.item():.8f}')print(f'Prediction after training: f(5) = {forward(5).item():.3f}')# 绘制图片plt.plot(x,y, 'o')plt.plot(x,2*x+20, 'r')plt.plot(x,w.item()*x+b.item(),'b')plt.show()\n","tags":["深度学习"]},{"title":"关于16系显卡无法运行yolo_v8的解决方案","url":"/2023/02/07/%E5%85%B3%E4%BA%8E16%E7%B3%BB%E6%98%BE%E5%8D%A1%E6%97%A0%E6%B3%95%E8%BF%90%E8%A1%8Cyolo-v8%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","content":"问题描述本人笔记本配置CPU:I9-9300H，GPU：GTX1660Ti，在使用yolo_v8进行深度学习的过程中发现在训练loss计算一直是Nan，起初考虑过是不是学习率太大导致，后来降低学习率，情况并没有改善，并且仅训练一个epoch时，loss计算仍为Nan。\n百度寻找解决方案，发现降低cuda版本为102，可以解决问题，但是Pytorch官方已经逐渐不维护10.x版本的cuda，所以另寻其他方法。\n查询NVIDIA官方网站，发现16系显卡没有Tensor core核心，不支持FP16半精度数据类型。\n解决方案通过阅读源码，yolo_v8版本在使用显卡训练是会使用FP16进行计算。因此只需要在判断是否是GPU训练时，将true改为false即可。\n更改位置如下：\n\nultralytics\\yolo\\engine\\trainer.py 第117行，改为self.amp &#x3D; False\n# Device# self.amp = self.device.type != &#x27;cpu&#x27;self.amp = False  #自行编写self.scaler = amp.GradScaler(enabled=self.amp)if self.device.type == &#x27;cpu&#x27;:    self.args.workers = 0  # faster CPU training as time dominated by inference, not dataloading\n\nultralytics\\yolo\\engine\\validator.py 第86行，改为self.args.half &#x3D; False\nif self.training:    self.device = trainer.device    self.data = trainer.data    model = trainer.ema.ema or trainer.model    #self.args.half = self.device.type != &#x27;cpu&#x27;  # force FP16 val during training    self.args.half = False #自行编写    model = model.half() if self.args.half else model.float()    self.model = model    self.loss = torch.zeros_like(trainer.loss_items, device=trainer.device)    elf.args.plots = trainer.epoch == trainer.epochs - 1  # always plot final epoch    model.eval()\n\nultralytics\\yolo\\engine\\validator.py 第98行，改为self.args.half &#x3D; False\nelse:    callbacks.add_integration_callbacks(self)    self.run_callbacks(&#x27;on_val_start&#x27;)    assert model is not None, &quot;Either trainer or model is needed for validation&quot;    self.device = select_device(self.args.device, self.args.batch)    #self.args.half &amp;= self.device.type != &#x27;cpu&#x27;    self.args.half = False #自行编写    model = AutoBackend(model, device=self.device, dnn=self.args.dnn, fp16=self.args.half)    self.model = model    stride, pt, jit, engine = model.stride, model.pt, model.jit, model.engine    imgsz = check_imgsz(self.args.imgsz, stride=stride) \n\n结尾经过实际测试，该方法可以解决yolo_v8代码在16系显卡上运行的问题，同时该方法也可运用于其他同样无Tensor core核心的显卡。\n","tags":["深度学习"]}]