[{"title":"3","url":"/2023/02/03/3/","content":""},{"title":"MarkDown基础语法","url":"/2023/02/03/MarkDown%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/","content":"标题样式#的数量表示标题的级别，注意 # 后加空格，最多支持到六级标题\n# 一级标题\n## 二级标题\n### 三级标题\n一级标题二级标题三级标题字体样式MarkDown字体样式有三种，斜体、粗体、粗斜体\n* 斜体 *                     斜体\n*粗体*                   粗体\n**粗斜体**          粗斜体\n分割线三个以上的 * 或 _ 构成分割线，且本行无其他内容\n***\n___\n\n\n引用在引用的段落前添加 &gt; 完成引用\n&gt; 这场漫长的战争伴随着整个人类文明，现在仍然胜负末定，虫子并没有被灭绝，它们照样傲行于天地之间，它们的数量也并不比人类出现前少。把人类看做虫子的三体人似乎忘记了一个事实：虫子从来就没有被真正战胜过。 \n\n这场漫长的战争伴随着整个人类文明，现在仍然胜负末定，虫子并没有被灭绝，它们照样傲行于天地之间，它们的数量也并不比人类出现前少。把人类看做虫子的三体人似乎忘记了一个事实：虫子从来就没有被真正战胜过。 \n\n也可采用多级引用\n\n引用一\n\n引用二\n\n引用三\n\n\n\n列表MarkDowe的列表有有序列表和无序列表\n有序列表\n第一项\n\n第二项\n\n\n无序列表* 第一项\n* 第二项\n\n第一项\n\n第二项\n\n\n代码块行内代码使用 &#96; 放在代码两端\n    这是一行经典的代码`print(“hello,world!”)`\n    这是一行经典的代码print(&quot;hello,world!&quot;)\n行间代码（代码块）使用 &#96;&#96;&#96; 放在代码块上下，可标注代码类型\na = &#x27;hello&#x27;b = &#x27;world!&#x27;print(f&#x27;&#123;a&#125;,&#123;b&#125;!&#x27;)\n","tags":["MarkDown"]},{"title":"线性回归梯度下降的np和Pytorch实现","url":"/2023/02/03/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84np%E5%92%8CPytorch%E5%AE%9E%E7%8E%B0/","content":"2022吴恩达机器学习 课程笔记\n本文为线性回归梯度下降的Python的代码实现\n基本公式 \n \n\n\n每次计算完令 , 进行数据更新，重复迭代，可令参数值不断逼近实际值\n基于np的代码实现import numpy as npimport matplotlib.pyplot as plt# 生成随机数据# 定义线性函数 y = x*2 + 20 + randomx = np.random.randint(0, 100, (10))y = x * 2 + 20 + np.random.randint(-5, 5,(10))print(x, y)# 计算损失函数def loss(x, y, w, b):    predict = x*w + b    loss = np.average((predict - y) ** 2) / 2    return predict, loss# 实现梯度下降# 定义部分参数epochs = 1000    # 迭代次数learning_rate = 0.0003    # 学习率w = 0b = 0    #初始化 w 和 bfor i in range(epochs):    predict, l = loss(x, y, w, b)    temp_w = w - learning_rate*np.average((predict-y)*x)    temp_b = b - learning_rate*np.average(predict-y)    w = temp_w    b = temp_bprint(w, b)# 绘制图片plt.plot(x,y, 'o')plt.plot(x,2*x+20, 'r')plt.plot(x,w*x+b,'b')plt.show()\n\n运行结果如下图所示：\n\n基于Pytorch的代码实现pytorch 可根据链式计算法则自动的计算梯度并将结果储存在w.grad中\nimport numpy as npimport torchimport matplotlib.pyplot as plt# 生成随机数据# 定义函数 y = x*2 + 20 + randomx = np.random.randint(0, 30, (10))y = x * 2 + 20 + np.random.randint(-5, 5,(10))w, b = 0, 0# 将数据转换为pytorch格式X = torch.tensor(x, dtype=torch.float32)Y = torch.tensor(y, dtype=torch.float32)w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)b = torch.tensor(10.0, dtype=torch.float32, requires_grad=True)# 向前传播def forward(x):    return w * x +b# 定义loss函数def loss(y, y_pred):    return ((y_pred - y)**2).mean()# 定义训练参数learning_rate = 0.0003epochs = 1000for epoch in range(epochs):    # 预测 向前传播    y_pred = forward(X)    # 计算loss    l = loss(Y, y_pred)    # 计算梯度 向后传播    l.backward()    # 更新权重    with torch.no_grad():        w -= learning_rate * w.grad        b -= learning_rate * b.grad    # 清零梯度    w.grad.zero_()    b.grad.zero_()    # 输出结果    if epoch % 10 == 0:        print(f'epoch {epoch+1}: w = {w.item():.3f}, b = {b.item():.3f} loss = {l.item():.8f}')print(f'Prediction after training: f(5) = {forward(5).item():.3f}')# 绘制图片plt.plot(x,y, 'o')plt.plot(x,2*x+20, 'r')plt.plot(x,w.item()*x+b.item(),'b')plt.show()\n","tags":["深度学习"]}]